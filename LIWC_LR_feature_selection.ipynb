{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LIWC_LR_feature_selection",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alenabozny/context-augmentation/blob/master/LIWC_LR_feature_selection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBrePjB5rxXI"
      },
      "source": [
        "**Mount Google Drive to the Notebook. This allows us to load datasets that are copyied to the GD directory.**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3MTQPfDHF2S",
        "outputId": "350e05f1-aad7-4dd1-a015-48eedc2cee57"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDkjxvO0sDVJ"
      },
      "source": [
        "**Load the dataset (LIWC features for CRED/NONCRED data)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "mwoht0ACHcgm",
        "outputId": "43795e25-8316-4ff2-a064-723631f63fe3"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "liwc_data = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/LIWC_paragrafy.csv\", sep=\";\",decimal=',', header=0)\n",
        "\n",
        "liwc_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Body</th>\n",
              "      <th>Rate</th>\n",
              "      <th>WC</th>\n",
              "      <th>Analytic</th>\n",
              "      <th>Clout</th>\n",
              "      <th>Authentic</th>\n",
              "      <th>Tone</th>\n",
              "      <th>WPS</th>\n",
              "      <th>Sixltr</th>\n",
              "      <th>Dic</th>\n",
              "      <th>function</th>\n",
              "      <th>pronoun</th>\n",
              "      <th>ppron</th>\n",
              "      <th>i</th>\n",
              "      <th>we</th>\n",
              "      <th>you</th>\n",
              "      <th>shehe</th>\n",
              "      <th>they</th>\n",
              "      <th>ipron</th>\n",
              "      <th>article</th>\n",
              "      <th>prep</th>\n",
              "      <th>auxverb</th>\n",
              "      <th>adverb</th>\n",
              "      <th>conj</th>\n",
              "      <th>negate</th>\n",
              "      <th>verb</th>\n",
              "      <th>adj</th>\n",
              "      <th>compare</th>\n",
              "      <th>interrog</th>\n",
              "      <th>number</th>\n",
              "      <th>quant</th>\n",
              "      <th>affect</th>\n",
              "      <th>posemo</th>\n",
              "      <th>negemo</th>\n",
              "      <th>anx</th>\n",
              "      <th>anger</th>\n",
              "      <th>sad</th>\n",
              "      <th>social</th>\n",
              "      <th>family</th>\n",
              "      <th>friend</th>\n",
              "      <th>...</th>\n",
              "      <th>health</th>\n",
              "      <th>sexual</th>\n",
              "      <th>ingest</th>\n",
              "      <th>drives</th>\n",
              "      <th>affiliation</th>\n",
              "      <th>achieve</th>\n",
              "      <th>power</th>\n",
              "      <th>reward</th>\n",
              "      <th>risk</th>\n",
              "      <th>focuspast</th>\n",
              "      <th>focuspresent</th>\n",
              "      <th>focusfuture</th>\n",
              "      <th>relativ</th>\n",
              "      <th>motion</th>\n",
              "      <th>space</th>\n",
              "      <th>time</th>\n",
              "      <th>work</th>\n",
              "      <th>leisure</th>\n",
              "      <th>home</th>\n",
              "      <th>money</th>\n",
              "      <th>relig</th>\n",
              "      <th>death</th>\n",
              "      <th>informal</th>\n",
              "      <th>swear</th>\n",
              "      <th>netspeak</th>\n",
              "      <th>assent</th>\n",
              "      <th>nonflu</th>\n",
              "      <th>filler</th>\n",
              "      <th>AllPunc</th>\n",
              "      <th>Period</th>\n",
              "      <th>Comma</th>\n",
              "      <th>Colon</th>\n",
              "      <th>SemiC</th>\n",
              "      <th>QMark</th>\n",
              "      <th>Exclam</th>\n",
              "      <th>Dash</th>\n",
              "      <th>Quote</th>\n",
              "      <th>Apostro</th>\n",
              "      <th>Parenth</th>\n",
              "      <th>OtherP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Statins available in the United States include...</td>\n",
              "      <td>CRED</td>\n",
              "      <td>56</td>\n",
              "      <td>98.29</td>\n",
              "      <td>76.25</td>\n",
              "      <td>2.24</td>\n",
              "      <td>25.77</td>\n",
              "      <td>18.67</td>\n",
              "      <td>33.93</td>\n",
              "      <td>60.71</td>\n",
              "      <td>33.93</td>\n",
              "      <td>7.14</td>\n",
              "      <td>5.36</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.79</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.57</td>\n",
              "      <td>1.79</td>\n",
              "      <td>7.14</td>\n",
              "      <td>14.29</td>\n",
              "      <td>3.57</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.79</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.93</td>\n",
              "      <td>7.14</td>\n",
              "      <td>5.36</td>\n",
              "      <td>0.00</td>\n",
              "      <td>5.36</td>\n",
              "      <td>3.57</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.14</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>5.36</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>5.36</td>\n",
              "      <td>1.79</td>\n",
              "      <td>1.79</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.79</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.79</td>\n",
              "      <td>8.93</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.14</td>\n",
              "      <td>0.00</td>\n",
              "      <td>5.36</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.79</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>44.64</td>\n",
              "      <td>8.93</td>\n",
              "      <td>10.71</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>25.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Statins are one of the most common medicines p...</td>\n",
              "      <td>CRED</td>\n",
              "      <td>53</td>\n",
              "      <td>93.26</td>\n",
              "      <td>93.42</td>\n",
              "      <td>5.35</td>\n",
              "      <td>61.55</td>\n",
              "      <td>17.67</td>\n",
              "      <td>13.21</td>\n",
              "      <td>92.45</td>\n",
              "      <td>50.94</td>\n",
              "      <td>15.09</td>\n",
              "      <td>9.43</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.66</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.77</td>\n",
              "      <td>5.66</td>\n",
              "      <td>7.55</td>\n",
              "      <td>20.75</td>\n",
              "      <td>5.66</td>\n",
              "      <td>3.77</td>\n",
              "      <td>3.77</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.09</td>\n",
              "      <td>11.32</td>\n",
              "      <td>9.43</td>\n",
              "      <td>0.00</td>\n",
              "      <td>5.66</td>\n",
              "      <td>3.77</td>\n",
              "      <td>1.89</td>\n",
              "      <td>1.89</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.32</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>9.43</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.89</td>\n",
              "      <td>11.32</td>\n",
              "      <td>5.66</td>\n",
              "      <td>1.89</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3.77</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.89</td>\n",
              "      <td>11.32</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.43</td>\n",
              "      <td>0.00</td>\n",
              "      <td>7.55</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.89</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.77</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.89</td>\n",
              "      <td>1.89</td>\n",
              "      <td>1.89</td>\n",
              "      <td>0</td>\n",
              "      <td>20.75</td>\n",
              "      <td>11.32</td>\n",
              "      <td>7.55</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.89</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>They work on an enzyme that is used by our bod...</td>\n",
              "      <td>CRED</td>\n",
              "      <td>84</td>\n",
              "      <td>74.10</td>\n",
              "      <td>90.47</td>\n",
              "      <td>6.50</td>\n",
              "      <td>25.77</td>\n",
              "      <td>21.00</td>\n",
              "      <td>17.86</td>\n",
              "      <td>94.05</td>\n",
              "      <td>50.00</td>\n",
              "      <td>13.10</td>\n",
              "      <td>7.14</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.95</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.19</td>\n",
              "      <td>5.95</td>\n",
              "      <td>5.95</td>\n",
              "      <td>15.48</td>\n",
              "      <td>7.14</td>\n",
              "      <td>3.57</td>\n",
              "      <td>9.52</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.10</td>\n",
              "      <td>4.76</td>\n",
              "      <td>3.57</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.19</td>\n",
              "      <td>4.76</td>\n",
              "      <td>2.38</td>\n",
              "      <td>2.38</td>\n",
              "      <td>1.19</td>\n",
              "      <td>1.19</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.52</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>13.10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.19</td>\n",
              "      <td>14.29</td>\n",
              "      <td>5.95</td>\n",
              "      <td>2.38</td>\n",
              "      <td>3.57</td>\n",
              "      <td>1.19</td>\n",
              "      <td>1.19</td>\n",
              "      <td>1.19</td>\n",
              "      <td>10.71</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.52</td>\n",
              "      <td>0.00</td>\n",
              "      <td>8.33</td>\n",
              "      <td>1.19</td>\n",
              "      <td>2.38</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.38</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.19</td>\n",
              "      <td>1.19</td>\n",
              "      <td>1.19</td>\n",
              "      <td>0</td>\n",
              "      <td>16.67</td>\n",
              "      <td>5.95</td>\n",
              "      <td>8.33</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.38</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Yep, that’s right…our bodies make cholesterol,...</td>\n",
              "      <td>CRED</td>\n",
              "      <td>76</td>\n",
              "      <td>64.39</td>\n",
              "      <td>85.38</td>\n",
              "      <td>19.27</td>\n",
              "      <td>25.77</td>\n",
              "      <td>19.00</td>\n",
              "      <td>19.74</td>\n",
              "      <td>93.42</td>\n",
              "      <td>50.00</td>\n",
              "      <td>11.84</td>\n",
              "      <td>5.26</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.26</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>6.58</td>\n",
              "      <td>5.26</td>\n",
              "      <td>14.47</td>\n",
              "      <td>7.89</td>\n",
              "      <td>5.26</td>\n",
              "      <td>10.53</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.84</td>\n",
              "      <td>5.26</td>\n",
              "      <td>3.95</td>\n",
              "      <td>2.63</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.32</td>\n",
              "      <td>5.26</td>\n",
              "      <td>2.63</td>\n",
              "      <td>2.63</td>\n",
              "      <td>1.32</td>\n",
              "      <td>1.32</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.89</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>13.16</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.32</td>\n",
              "      <td>13.16</td>\n",
              "      <td>5.26</td>\n",
              "      <td>1.32</td>\n",
              "      <td>3.95</td>\n",
              "      <td>1.32</td>\n",
              "      <td>1.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>9.21</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.16</td>\n",
              "      <td>1.32</td>\n",
              "      <td>10.53</td>\n",
              "      <td>1.32</td>\n",
              "      <td>1.32</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.63</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.32</td>\n",
              "      <td>1.32</td>\n",
              "      <td>1.32</td>\n",
              "      <td>0</td>\n",
              "      <td>18.42</td>\n",
              "      <td>6.58</td>\n",
              "      <td>9.21</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.63</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>That’s because cholesterol is vital for our su...</td>\n",
              "      <td>CRED</td>\n",
              "      <td>101</td>\n",
              "      <td>92.29</td>\n",
              "      <td>61.69</td>\n",
              "      <td>29.80</td>\n",
              "      <td>1.00</td>\n",
              "      <td>25.25</td>\n",
              "      <td>18.81</td>\n",
              "      <td>83.17</td>\n",
              "      <td>43.56</td>\n",
              "      <td>5.94</td>\n",
              "      <td>1.98</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.98</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3.96</td>\n",
              "      <td>7.92</td>\n",
              "      <td>14.85</td>\n",
              "      <td>4.95</td>\n",
              "      <td>3.96</td>\n",
              "      <td>8.91</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.93</td>\n",
              "      <td>4.95</td>\n",
              "      <td>2.97</td>\n",
              "      <td>1.98</td>\n",
              "      <td>2.97</td>\n",
              "      <td>0.99</td>\n",
              "      <td>5.94</td>\n",
              "      <td>0.99</td>\n",
              "      <td>4.95</td>\n",
              "      <td>1.98</td>\n",
              "      <td>1.98</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.96</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>10.89</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>10.89</td>\n",
              "      <td>1.98</td>\n",
              "      <td>0.99</td>\n",
              "      <td>4.95</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.97</td>\n",
              "      <td>0.99</td>\n",
              "      <td>4.95</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.86</td>\n",
              "      <td>0.99</td>\n",
              "      <td>8.91</td>\n",
              "      <td>3.96</td>\n",
              "      <td>1.98</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>20.79</td>\n",
              "      <td>3.96</td>\n",
              "      <td>3.96</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.99</td>\n",
              "      <td>1.98</td>\n",
              "      <td>0.99</td>\n",
              "      <td>5.94</td>\n",
              "      <td>2.97</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 95 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Body  Rate  ...  Parenth  OtherP\n",
              "0  Statins available in the United States include...  CRED  ...    25.00    0.00\n",
              "1  Statins are one of the most common medicines p...  CRED  ...     0.00    0.00\n",
              "2  They work on an enzyme that is used by our bod...  CRED  ...     0.00    0.00\n",
              "3  Yep, that’s right…our bodies make cholesterol,...  CRED  ...     0.00    0.00\n",
              "4  That’s because cholesterol is vital for our su...  CRED  ...     5.94    2.97\n",
              "\n",
              "[5 rows x 95 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pIVeBF5OcIY"
      },
      "source": [
        "liwc_data = liwc_data[0:1917:3]\n",
        "liwc_data_np = liwc_data.values\n",
        "X = liwc_data_np[:, 2:]\n",
        "Y = liwc_data_np[:,1]\n",
        "\n",
        "def y_to_binary(Y):\n",
        "  def label_to_0_1(lbl):\n",
        "    if lbl=='CRED':\n",
        "      return 1\n",
        "    else:\n",
        "      return 0\n",
        "\n",
        "  Y_mapped = map(label_to_0_1, Y)\n",
        "  return np.array(list(Y_mapped))\n",
        "\n",
        "Y = y_to_binary(Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kU0zIrhpYWim",
        "outputId": "11604c0b-a89c-45d2-9494-51960421b02f"
      },
      "source": [
        "np.shape(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(639, 93)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0L2eeS-wZiki"
      },
      "source": [
        "## **Recursive Feature Elimination (on Logistic Regression model)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBgr_ZbIZxsx"
      },
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtkDtxFljcOy",
        "outputId": "31a1fdba-e2cb-461f-fbc7-acad637e2bd0"
      },
      "source": [
        "def get_n_most_important(num_features):\n",
        "  model = LogisticRegression(max_iter=10000)\n",
        "  rfe = RFE(model, num_features, verbose=0)\n",
        "  fit = rfe.fit(X, Y)\n",
        "\n",
        "  # print(\"Num Features: %s\" % (fit.n_features_))\n",
        "  # print(\"Selected Features: %s\" % (fit.support_))\n",
        "  # print(\"Feature Ranking: %s\" % (fit.ranking_))\n",
        "\n",
        "  features = liwc_data.columns.values[2:]\n",
        "  important_features = []\n",
        "\n",
        "  for f in list(zip(features, fit.support_)):\n",
        "    if f[1]:\n",
        "      important_features.append(f[0])\n",
        "\n",
        "  return important_features\n",
        "\n",
        "important_features = get_n_most_important(50)\n",
        "print(important_features)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['function', 'pronoun', 'i', 'we', 'you', 'shehe', 'they', 'ipron', 'article', 'prep', 'auxverb', 'conj', 'compare', 'interrog', 'affect', 'posemo', 'negemo', 'anx', 'sad', 'family', 'friend', 'female', 'male', 'cause', 'certain', 'differ', 'percept', 'see', 'hear', 'feel', 'sexual', 'drives', 'affiliation', 'power', 'reward', 'risk', 'focusfuture', 'leisure', 'home', 'money', 'informal', 'swear', 'assent', 'nonflu', 'Period', 'SemiC', 'QMark', 'Exclam', 'Dash', 'Apostro']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCSvy3essahT"
      },
      "source": [
        "## **Build and test LR model on the reduced dataset (only the most important features)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "DdpbmmGBrXhU",
        "outputId": "c3efca68-36d3-4e68-bf22-4914fcfb4ba1"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "shuffle(liwc_data[important_features]).head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>function</th>\n",
              "      <th>pronoun</th>\n",
              "      <th>i</th>\n",
              "      <th>we</th>\n",
              "      <th>you</th>\n",
              "      <th>shehe</th>\n",
              "      <th>they</th>\n",
              "      <th>ipron</th>\n",
              "      <th>article</th>\n",
              "      <th>prep</th>\n",
              "      <th>auxverb</th>\n",
              "      <th>conj</th>\n",
              "      <th>compare</th>\n",
              "      <th>interrog</th>\n",
              "      <th>affect</th>\n",
              "      <th>posemo</th>\n",
              "      <th>negemo</th>\n",
              "      <th>anx</th>\n",
              "      <th>sad</th>\n",
              "      <th>family</th>\n",
              "      <th>friend</th>\n",
              "      <th>female</th>\n",
              "      <th>male</th>\n",
              "      <th>cause</th>\n",
              "      <th>certain</th>\n",
              "      <th>differ</th>\n",
              "      <th>percept</th>\n",
              "      <th>see</th>\n",
              "      <th>hear</th>\n",
              "      <th>feel</th>\n",
              "      <th>sexual</th>\n",
              "      <th>drives</th>\n",
              "      <th>affiliation</th>\n",
              "      <th>power</th>\n",
              "      <th>reward</th>\n",
              "      <th>risk</th>\n",
              "      <th>focusfuture</th>\n",
              "      <th>leisure</th>\n",
              "      <th>home</th>\n",
              "      <th>money</th>\n",
              "      <th>informal</th>\n",
              "      <th>swear</th>\n",
              "      <th>assent</th>\n",
              "      <th>nonflu</th>\n",
              "      <th>Period</th>\n",
              "      <th>SemiC</th>\n",
              "      <th>QMark</th>\n",
              "      <th>Exclam</th>\n",
              "      <th>Dash</th>\n",
              "      <th>Apostro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1050</th>\n",
              "      <td>54.76</td>\n",
              "      <td>9.52</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.38</td>\n",
              "      <td>7.14</td>\n",
              "      <td>9.52</td>\n",
              "      <td>7.14</td>\n",
              "      <td>11.90</td>\n",
              "      <td>7.14</td>\n",
              "      <td>4.76</td>\n",
              "      <td>0.00</td>\n",
              "      <td>7.14</td>\n",
              "      <td>2.38</td>\n",
              "      <td>4.76</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>4.76</td>\n",
              "      <td>14.29</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.14</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.38</td>\n",
              "      <td>0.00</td>\n",
              "      <td>4.76</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.14</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>525</th>\n",
              "      <td>42.31</td>\n",
              "      <td>5.77</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.77</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>9.62</td>\n",
              "      <td>13.46</td>\n",
              "      <td>7.69</td>\n",
              "      <td>3.85</td>\n",
              "      <td>1.92</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3.85</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3.85</td>\n",
              "      <td>1.92</td>\n",
              "      <td>1.92</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.77</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.92</td>\n",
              "      <td>1.92</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.92</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.77</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3.85</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.92</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.77</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.92</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1791</th>\n",
              "      <td>48.57</td>\n",
              "      <td>22.86</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.43</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>11.43</td>\n",
              "      <td>0.00</td>\n",
              "      <td>17.14</td>\n",
              "      <td>2.86</td>\n",
              "      <td>5.71</td>\n",
              "      <td>5.71</td>\n",
              "      <td>2.86</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.71</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.86</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.86</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.57</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>279</th>\n",
              "      <td>44.83</td>\n",
              "      <td>8.05</td>\n",
              "      <td>3.45</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.30</td>\n",
              "      <td>2.30</td>\n",
              "      <td>8.05</td>\n",
              "      <td>14.94</td>\n",
              "      <td>3.45</td>\n",
              "      <td>4.60</td>\n",
              "      <td>2.30</td>\n",
              "      <td>2.30</td>\n",
              "      <td>4.60</td>\n",
              "      <td>2.30</td>\n",
              "      <td>2.30</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.15</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.30</td>\n",
              "      <td>2.30</td>\n",
              "      <td>2.30</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.05</td>\n",
              "      <td>1.15</td>\n",
              "      <td>5.75</td>\n",
              "      <td>1.15</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.15</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.60</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.45</td>\n",
              "      <td>1.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>291</th>\n",
              "      <td>45.24</td>\n",
              "      <td>7.14</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.76</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.38</td>\n",
              "      <td>11.90</td>\n",
              "      <td>11.90</td>\n",
              "      <td>9.52</td>\n",
              "      <td>4.76</td>\n",
              "      <td>4.76</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.38</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.38</td>\n",
              "      <td>2.38</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.38</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.38</td>\n",
              "      <td>2.38</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.90</td>\n",
              "      <td>0.00</td>\n",
              "      <td>11.90</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.38</td>\n",
              "      <td>2.38</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.14</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.38</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      function  pronoun     i   we    you  ...  SemiC  QMark  Exclam  Dash  Apostro\n",
              "1050     54.76     9.52  0.00  0.0   0.00  ...    0.0    0.0     0.0  0.00     0.00\n",
              "525      42.31     5.77  0.00  0.0   5.77  ...    0.0    0.0     0.0  1.92     0.00\n",
              "1791     48.57    22.86  0.00  0.0  11.43  ...    0.0    0.0     0.0  0.00     0.00\n",
              "279      44.83     8.05  3.45  0.0   0.00  ...    0.0    0.0     0.0  3.45     1.15\n",
              "291      45.24     7.14  0.00  0.0   4.76  ...    0.0    0.0     0.0  0.00     2.38\n",
              "\n",
              "[5 rows x 50 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sknDc9KCrsKO",
        "outputId": "950ee72a-a8c4-496a-b2fd-608dafd00410"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn import preprocessing as p\n",
        "\n",
        "\n",
        "VALIDATION_SPLIT = 0.2\n",
        "\n",
        "def build_logit(liwc_data, important_features):\n",
        "  # split the data into a training set and a validation set\n",
        "  min_max_scaler = p.MinMaxScaler()\n",
        "  liwc_shuffled = shuffle(liwc_data)\n",
        "  X = liwc_shuffled[important_features].values[:, 2:]\n",
        "  X = min_max_scaler.fit_transform(X)\n",
        "  Y = liwc_shuffled.values[:,1]\n",
        "  Y = y_to_binary(Y)\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=VALIDATION_SPLIT)\n",
        "  logreg = LogisticRegression()\n",
        "  logreg.fit(X_train, y_train)\n",
        "\n",
        "  y_pred = logreg.predict(X_test)\n",
        "  print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))\n",
        "  print('F1: {:.2f}'.format(metrics.f1_score(y_test, y_pred, average='weighted')))\n",
        "  # return logreg.score(X_test, y_test)\n",
        "  return (metrics.f1_score(y_test, y_pred, average='weighted'), y_test, y_pred)\n",
        "\n",
        "f1, y_test, y_pred = build_logit(liwc_data, important_features)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of logistic regression classifier on test set: 0.74\n",
            "F1: 0.73\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "am8SbmC5M7J8"
      },
      "source": [
        " **For N iterations check how important feature addition affects the mean accuracy of the model.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "Z6D-YbtUM5C_",
        "outputId": "97859df2-42fc-4fe7-d084-e37fba4af6d3"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "N = 90\n",
        "\n",
        "mean_f1 = []\n",
        "\n",
        "for i in range(3, N, 9):\n",
        "  print('Num features: %i' %i)\n",
        "  important_features = get_n_most_important(i)\n",
        "  f1, _, _ = build_logit(liwc_data, important_features)\n",
        "  # mean_accuracies.append(acc)\n",
        "  mean_f1.append(f1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num features: 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-2c8e6449063f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Num features: %i'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mimportant_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_n_most_important\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_logit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mliwc_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimportant_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;31m# mean_accuracies.append(acc)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-4de4a1fcdc01>\u001b[0m in \u001b[0;36mget_n_most_important\u001b[0;34m(num_features)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mrfe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRFE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mfit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;31m# print(\"Num Features: %s\" % (fit.n_features_))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/feature_selection/_rfe.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \"\"\"\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/feature_selection/_rfe.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, step_score)\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Fitting estimator with %d features.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msupport_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0;31m# Get coefs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1599\u001b[0m                       \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m                       sample_weight=sample_weight)\n\u001b[0;32m-> 1601\u001b[0;31m             for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n\u001b[0m\u001b[1;32m   1602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0mfold_coefs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfold_coefs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1039\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[1;32m    934\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"L-BFGS-B\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 936\u001b[0;31m                 \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"iprint\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0miprint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"gtol\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"maxiter\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    937\u001b[0m             )\n\u001b[1;32m    938\u001b[0m             n_iter_i = _check_optimize_result(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m--> 610\u001b[0;31m                                 callback=callback, **options)\n\u001b[0m\u001b[1;32m    611\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m         return _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_loss_and_grad\u001b[0;34m(w, X, y, alpha, sample_weight)\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m     \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_intercept_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_intercept_dot\u001b[0;34m(w, X, y)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0myz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     if (sparse.issparse(a) and sparse.issparse(b)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "w4hF5Se3SV8t",
        "outputId": "e972aae7-ab49-4bc0-bd6c-498a30257d28"
      },
      "source": [
        "plt.figure()\n",
        "plt.plot(range(3, N, 9),mean_f1, label='F1 change by number of features in LogisticRegression model')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pO5StreQBvP"
      },
      "source": [
        "**Train on the given category set, then test on the external category.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "431s-Ax7QAyo",
        "outputId": "c94aef5e-0d69-4bfa-d524-f41df681983c"
      },
      "source": [
        "import pickle\n",
        "\n",
        "sent_cat = pd.read_pickle('/content/drive/My Drive/Colab Notebooks/sentences_rates_categories.p')\n",
        "sent_cat[\"body\"].describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count     10649\n",
              "unique    10143\n",
              "top           .\n",
              "freq         26\n",
              "Name: body, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmtdRsbZxZfS",
        "outputId": "0ed4553d-7fc5-46ef-9f67-b470760cda9e"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# f1, y_test, y_pred = build_logit(liwc_data, get_n_most_important(74))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.48      0.59        48\n",
            "           1       0.74      0.91      0.82        80\n",
            "\n",
            "    accuracy                           0.75       128\n",
            "   macro avg       0.76      0.70      0.70       128\n",
            "weighted avg       0.75      0.75      0.73       128\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vvWJugnx3Ph",
        "outputId": "468ef713-597b-41cb-8ccb-9b11ad7b9cde"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(confusion_matrix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[23 25]\n",
            " [ 7 73]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 760
        },
        "id": "2BGke5dH_Fv_",
        "outputId": "eb2b5369-a26c-4b3f-a1c5-f7eaf0af6201"
      },
      "source": [
        "!pip install spacytextblob"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting spacytextblob\n",
            "  Downloading https://files.pythonhosted.org/packages/56/34/13b9d75a9e3ba30eac115dd0ecbe17d65921a721345b8d915b9ffccc0123/spacytextblob-0.1.7-py3-none-any.whl\n",
            "Requirement already satisfied: textblob<0.16.0,>=0.15.3 in /usr/local/lib/python3.7/dist-packages (from spacytextblob) (0.15.3)\n",
            "Collecting spacy<3.0.0,>=2.3.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/89/1539c4024c339650c222b0b2ca2b3e3f13523b7a02671f8001b7b1cee6f2/spacy-2.3.5-cp37-cp37m-manylinux2014_x86_64.whl (10.4MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4MB 6.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.7/dist-packages (from textblob<0.16.0,>=0.15.3->spacytextblob) (3.2.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.3.2->spacytextblob) (3.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.3.2->spacytextblob) (0.8.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.3.2->spacytextblob) (1.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.3.2->spacytextblob) (4.41.1)\n",
            "Collecting thinc<7.5.0,>=7.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/92/71ab278f865f7565c37ed6917d0f23342e4f9a0633013113bd435cf0a691/thinc-7.4.5-cp37-cp37m-manylinux2014_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 41.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.3.2->spacytextblob) (2.23.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.3.2->spacytextblob) (54.0.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.3.2->spacytextblob) (2.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.3.2->spacytextblob) (1.0.5)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.3.2->spacytextblob) (0.4.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.3.2->spacytextblob) (1.1.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.3.2->spacytextblob) (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.3.2->spacytextblob) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob<0.16.0,>=0.15.3->spacytextblob) (1.15.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<3.0.0,>=2.3.2->spacytextblob) (3.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.3.2->spacytextblob) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.3.2->spacytextblob) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.3.2->spacytextblob) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.3.2->spacytextblob) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<3.0.0,>=2.3.2->spacytextblob) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<3.0.0,>=2.3.2->spacytextblob) (3.7.4.3)\n",
            "Installing collected packages: thinc, spacy, spacytextblob\n",
            "  Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "Successfully installed spacy-2.3.5 spacytextblob-0.1.7 thinc-7.4.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "spacy",
                  "thinc"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMHiocjs_e0v"
      },
      "source": [
        "# The Model\r\n",
        "Features:\r\n",
        "- TFIDF\r\n",
        "- NER\r\n",
        "- POS\r\n",
        "- LIWC\r\n",
        "- sentiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADi-UtDH_rFN"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\r\n",
        "from sklearn.utils import shuffle\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn import metrics\r\n",
        "from sklearn import preprocessing as p\r\n",
        "\r\n",
        "VALIDATION_SPLIT = 0.2\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CZN5Pq3I5cd",
        "outputId": "95a2cf4f-e302-4650-8920-722f9119ab16"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import spacy\n",
        "from spacytextblob.spacytextblob import SpacyTextBlob\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "spacy_text_blob = SpacyTextBlob()\n",
        "nlp.add_pipe(spacy_text_blob)\n",
        "\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk import word_tokenize, sent_tokenize\n",
        "\n",
        "# important_features = get_n_most_important(50)\n",
        "liwc_data_np = liwc_data.values\n",
        "X_liwc = liwc_data_np[:, 2:]\n",
        "min_max_scaler = p.MinMaxScaler()\n",
        "\n",
        "liwc_shuffled = shuffle(liwc_data)\n",
        "corpus = liwc_shuffled['Body']\n",
        "corpus_removed_numbers = [re.sub(r'\\d+', '', s) for s in corpus]\n",
        "\n",
        "Y = liwc_shuffled['Rate']\n",
        "Y = y_to_binary(Y)\n",
        "\n",
        "corpus_tokenized = []\n",
        "stemmer= PorterStemmer()\n",
        "\n",
        "for s in corpus_removed_numbers:\n",
        "  tokens = word_tokenize(s)\n",
        "  stemmed_tokens = [stemmer.stem(word) for word in tokens]\n",
        "  corpus_tokenized.append(\" \".join(stemmed_tokens))\n",
        "\n",
        "X_sentiment = []\n",
        "for s in corpus:\n",
        "  doc = nlp(s)\n",
        "  X_sentiment.append([doc._.sentiment.polarity,\n",
        "                     doc._.sentiment.subjectivity]\n",
        "                     )\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_tfidf = vectorizer.fit_transform(corpus_tokenized)\n",
        "X_tfidf = np.array(X_tfidf.toarray())\n",
        "X = np.concatenate((X_tfidf, X_liwc, X_sentiment), axis=1)\n",
        "X = min_max_scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=VALIDATION_SPLIT)\n",
        "\n",
        "def eval_and_print_metrics(clf, X_train, y_train, X_test, y_test):\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    print(\"F1 score on test set: \"\n",
        "          \"%0.3f\" % metrics.f1_score(y_test, y_pred, average='weighted'))\n",
        "    print(\"-\" * 10)\n",
        "\n",
        "clf = MLPClassifier(random_state=1, max_iter=2000, solver='adam', hidden_layer_sizes=(20,5)).fit(X_train, y_train)\n",
        "\n",
        "eval_and_print_metrics(clf, X_train, y_train, X_test, y_test)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "F1 score on test set: 0.712\n",
            "----------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "-uJxgmQ5yFOl",
        "outputId": "f5a9c779-6468-45da-aa60-c13241f9cf22"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# min_max_scaler = p.MinMaxScaler()\n",
        "\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=VALIDATION_SPLIT)\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "logit_roc_auc = roc_auc_score(y_test, logreg.predict(X_test))\n",
        "fpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(X_test)[:,1])\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.savefig('Log_ROC')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}