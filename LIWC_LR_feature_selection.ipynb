{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LIWC_LR_feature_selection",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alenabozny/context-augmentation/blob/master/LIWC_LR_feature_selection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBrePjB5rxXI"
      },
      "source": [
        "**Mount Google Drive to the Notebook. This allows us to load datasets that are copyied to the GD directory.**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3MTQPfDHF2S",
        "outputId": "fd110915-05b8-4838-f240-2f32b815504c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDkjxvO0sDVJ"
      },
      "source": [
        "**Load the dataset (LIWC features for CRED/NONCRED data)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "mwoht0ACHcgm",
        "outputId": "5b980b58-02d8-4517-ad67-e5bed1c54b4f"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "liwc_data = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/LIWC_paragrafy.csv\", sep=\";\",decimal=',', header=0)\n",
        "\n",
        "liwc_data.head()"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Body</th>\n",
              "      <th>Rate</th>\n",
              "      <th>WC</th>\n",
              "      <th>Analytic</th>\n",
              "      <th>Clout</th>\n",
              "      <th>Authentic</th>\n",
              "      <th>Tone</th>\n",
              "      <th>WPS</th>\n",
              "      <th>Sixltr</th>\n",
              "      <th>Dic</th>\n",
              "      <th>function</th>\n",
              "      <th>pronoun</th>\n",
              "      <th>ppron</th>\n",
              "      <th>i</th>\n",
              "      <th>we</th>\n",
              "      <th>you</th>\n",
              "      <th>shehe</th>\n",
              "      <th>they</th>\n",
              "      <th>ipron</th>\n",
              "      <th>article</th>\n",
              "      <th>prep</th>\n",
              "      <th>auxverb</th>\n",
              "      <th>adverb</th>\n",
              "      <th>conj</th>\n",
              "      <th>negate</th>\n",
              "      <th>verb</th>\n",
              "      <th>adj</th>\n",
              "      <th>compare</th>\n",
              "      <th>interrog</th>\n",
              "      <th>number</th>\n",
              "      <th>quant</th>\n",
              "      <th>affect</th>\n",
              "      <th>posemo</th>\n",
              "      <th>negemo</th>\n",
              "      <th>anx</th>\n",
              "      <th>anger</th>\n",
              "      <th>sad</th>\n",
              "      <th>social</th>\n",
              "      <th>family</th>\n",
              "      <th>friend</th>\n",
              "      <th>...</th>\n",
              "      <th>health</th>\n",
              "      <th>sexual</th>\n",
              "      <th>ingest</th>\n",
              "      <th>drives</th>\n",
              "      <th>affiliation</th>\n",
              "      <th>achieve</th>\n",
              "      <th>power</th>\n",
              "      <th>reward</th>\n",
              "      <th>risk</th>\n",
              "      <th>focuspast</th>\n",
              "      <th>focuspresent</th>\n",
              "      <th>focusfuture</th>\n",
              "      <th>relativ</th>\n",
              "      <th>motion</th>\n",
              "      <th>space</th>\n",
              "      <th>time</th>\n",
              "      <th>work</th>\n",
              "      <th>leisure</th>\n",
              "      <th>home</th>\n",
              "      <th>money</th>\n",
              "      <th>relig</th>\n",
              "      <th>death</th>\n",
              "      <th>informal</th>\n",
              "      <th>swear</th>\n",
              "      <th>netspeak</th>\n",
              "      <th>assent</th>\n",
              "      <th>nonflu</th>\n",
              "      <th>filler</th>\n",
              "      <th>AllPunc</th>\n",
              "      <th>Period</th>\n",
              "      <th>Comma</th>\n",
              "      <th>Colon</th>\n",
              "      <th>SemiC</th>\n",
              "      <th>QMark</th>\n",
              "      <th>Exclam</th>\n",
              "      <th>Dash</th>\n",
              "      <th>Quote</th>\n",
              "      <th>Apostro</th>\n",
              "      <th>Parenth</th>\n",
              "      <th>OtherP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Statins available in the United States include...</td>\n",
              "      <td>CRED</td>\n",
              "      <td>56</td>\n",
              "      <td>98.29</td>\n",
              "      <td>76.25</td>\n",
              "      <td>2.24</td>\n",
              "      <td>25.77</td>\n",
              "      <td>18.67</td>\n",
              "      <td>33.93</td>\n",
              "      <td>60.71</td>\n",
              "      <td>33.93</td>\n",
              "      <td>7.14</td>\n",
              "      <td>5.36</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.79</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.57</td>\n",
              "      <td>1.79</td>\n",
              "      <td>7.14</td>\n",
              "      <td>14.29</td>\n",
              "      <td>3.57</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.79</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.93</td>\n",
              "      <td>7.14</td>\n",
              "      <td>5.36</td>\n",
              "      <td>0.00</td>\n",
              "      <td>5.36</td>\n",
              "      <td>3.57</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.14</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>5.36</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>5.36</td>\n",
              "      <td>1.79</td>\n",
              "      <td>1.79</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.79</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.79</td>\n",
              "      <td>8.93</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.14</td>\n",
              "      <td>0.00</td>\n",
              "      <td>5.36</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.79</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>44.64</td>\n",
              "      <td>8.93</td>\n",
              "      <td>10.71</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>25.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Statins are one of the most common medicines p...</td>\n",
              "      <td>CRED</td>\n",
              "      <td>53</td>\n",
              "      <td>93.26</td>\n",
              "      <td>93.42</td>\n",
              "      <td>5.35</td>\n",
              "      <td>61.55</td>\n",
              "      <td>17.67</td>\n",
              "      <td>13.21</td>\n",
              "      <td>92.45</td>\n",
              "      <td>50.94</td>\n",
              "      <td>15.09</td>\n",
              "      <td>9.43</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.66</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.77</td>\n",
              "      <td>5.66</td>\n",
              "      <td>7.55</td>\n",
              "      <td>20.75</td>\n",
              "      <td>5.66</td>\n",
              "      <td>3.77</td>\n",
              "      <td>3.77</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.09</td>\n",
              "      <td>11.32</td>\n",
              "      <td>9.43</td>\n",
              "      <td>0.00</td>\n",
              "      <td>5.66</td>\n",
              "      <td>3.77</td>\n",
              "      <td>1.89</td>\n",
              "      <td>1.89</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.32</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>9.43</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.89</td>\n",
              "      <td>11.32</td>\n",
              "      <td>5.66</td>\n",
              "      <td>1.89</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3.77</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.89</td>\n",
              "      <td>11.32</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.43</td>\n",
              "      <td>0.00</td>\n",
              "      <td>7.55</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.89</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.77</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.89</td>\n",
              "      <td>1.89</td>\n",
              "      <td>1.89</td>\n",
              "      <td>0</td>\n",
              "      <td>20.75</td>\n",
              "      <td>11.32</td>\n",
              "      <td>7.55</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.89</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>They work on an enzyme that is used by our bod...</td>\n",
              "      <td>CRED</td>\n",
              "      <td>84</td>\n",
              "      <td>74.10</td>\n",
              "      <td>90.47</td>\n",
              "      <td>6.50</td>\n",
              "      <td>25.77</td>\n",
              "      <td>21.00</td>\n",
              "      <td>17.86</td>\n",
              "      <td>94.05</td>\n",
              "      <td>50.00</td>\n",
              "      <td>13.10</td>\n",
              "      <td>7.14</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.95</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.19</td>\n",
              "      <td>5.95</td>\n",
              "      <td>5.95</td>\n",
              "      <td>15.48</td>\n",
              "      <td>7.14</td>\n",
              "      <td>3.57</td>\n",
              "      <td>9.52</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.10</td>\n",
              "      <td>4.76</td>\n",
              "      <td>3.57</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.19</td>\n",
              "      <td>4.76</td>\n",
              "      <td>2.38</td>\n",
              "      <td>2.38</td>\n",
              "      <td>1.19</td>\n",
              "      <td>1.19</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.52</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>13.10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.19</td>\n",
              "      <td>14.29</td>\n",
              "      <td>5.95</td>\n",
              "      <td>2.38</td>\n",
              "      <td>3.57</td>\n",
              "      <td>1.19</td>\n",
              "      <td>1.19</td>\n",
              "      <td>1.19</td>\n",
              "      <td>10.71</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.52</td>\n",
              "      <td>0.00</td>\n",
              "      <td>8.33</td>\n",
              "      <td>1.19</td>\n",
              "      <td>2.38</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.38</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.19</td>\n",
              "      <td>1.19</td>\n",
              "      <td>1.19</td>\n",
              "      <td>0</td>\n",
              "      <td>16.67</td>\n",
              "      <td>5.95</td>\n",
              "      <td>8.33</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.38</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Yep, that’s right…our bodies make cholesterol,...</td>\n",
              "      <td>CRED</td>\n",
              "      <td>76</td>\n",
              "      <td>64.39</td>\n",
              "      <td>85.38</td>\n",
              "      <td>19.27</td>\n",
              "      <td>25.77</td>\n",
              "      <td>19.00</td>\n",
              "      <td>19.74</td>\n",
              "      <td>93.42</td>\n",
              "      <td>50.00</td>\n",
              "      <td>11.84</td>\n",
              "      <td>5.26</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.26</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>6.58</td>\n",
              "      <td>5.26</td>\n",
              "      <td>14.47</td>\n",
              "      <td>7.89</td>\n",
              "      <td>5.26</td>\n",
              "      <td>10.53</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.84</td>\n",
              "      <td>5.26</td>\n",
              "      <td>3.95</td>\n",
              "      <td>2.63</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.32</td>\n",
              "      <td>5.26</td>\n",
              "      <td>2.63</td>\n",
              "      <td>2.63</td>\n",
              "      <td>1.32</td>\n",
              "      <td>1.32</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.89</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>13.16</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.32</td>\n",
              "      <td>13.16</td>\n",
              "      <td>5.26</td>\n",
              "      <td>1.32</td>\n",
              "      <td>3.95</td>\n",
              "      <td>1.32</td>\n",
              "      <td>1.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>9.21</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.16</td>\n",
              "      <td>1.32</td>\n",
              "      <td>10.53</td>\n",
              "      <td>1.32</td>\n",
              "      <td>1.32</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.63</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.32</td>\n",
              "      <td>1.32</td>\n",
              "      <td>1.32</td>\n",
              "      <td>0</td>\n",
              "      <td>18.42</td>\n",
              "      <td>6.58</td>\n",
              "      <td>9.21</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.63</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>That’s because cholesterol is vital for our su...</td>\n",
              "      <td>CRED</td>\n",
              "      <td>101</td>\n",
              "      <td>92.29</td>\n",
              "      <td>61.69</td>\n",
              "      <td>29.80</td>\n",
              "      <td>1.00</td>\n",
              "      <td>25.25</td>\n",
              "      <td>18.81</td>\n",
              "      <td>83.17</td>\n",
              "      <td>43.56</td>\n",
              "      <td>5.94</td>\n",
              "      <td>1.98</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.98</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3.96</td>\n",
              "      <td>7.92</td>\n",
              "      <td>14.85</td>\n",
              "      <td>4.95</td>\n",
              "      <td>3.96</td>\n",
              "      <td>8.91</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.93</td>\n",
              "      <td>4.95</td>\n",
              "      <td>2.97</td>\n",
              "      <td>1.98</td>\n",
              "      <td>2.97</td>\n",
              "      <td>0.99</td>\n",
              "      <td>5.94</td>\n",
              "      <td>0.99</td>\n",
              "      <td>4.95</td>\n",
              "      <td>1.98</td>\n",
              "      <td>1.98</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.96</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>10.89</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>10.89</td>\n",
              "      <td>1.98</td>\n",
              "      <td>0.99</td>\n",
              "      <td>4.95</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.97</td>\n",
              "      <td>0.99</td>\n",
              "      <td>4.95</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.86</td>\n",
              "      <td>0.99</td>\n",
              "      <td>8.91</td>\n",
              "      <td>3.96</td>\n",
              "      <td>1.98</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>20.79</td>\n",
              "      <td>3.96</td>\n",
              "      <td>3.96</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.99</td>\n",
              "      <td>1.98</td>\n",
              "      <td>0.99</td>\n",
              "      <td>5.94</td>\n",
              "      <td>2.97</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 95 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Body  Rate  ...  Parenth  OtherP\n",
              "0  Statins available in the United States include...  CRED  ...    25.00    0.00\n",
              "1  Statins are one of the most common medicines p...  CRED  ...     0.00    0.00\n",
              "2  They work on an enzyme that is used by our bod...  CRED  ...     0.00    0.00\n",
              "3  Yep, that’s right…our bodies make cholesterol,...  CRED  ...     0.00    0.00\n",
              "4  That’s because cholesterol is vital for our su...  CRED  ...     5.94    2.97\n",
              "\n",
              "[5 rows x 95 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pIVeBF5OcIY"
      },
      "source": [
        "liwc_data_paragraphs = liwc_data[0:1917:3]\n",
        "\n",
        "def y_to_binary(Y):\n",
        "  def label_to_0_1(lbl):\n",
        "    if lbl=='CRED':\n",
        "      return 1\n",
        "    else:\n",
        "      return 0\n",
        "\n",
        "  Y_mapped = map(label_to_0_1, Y)\n",
        "  return np.array(list(Y_mapped))"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kU0zIrhpYWim",
        "outputId": "f58b8cfa-fd2e-4044-ed6a-c92feaa4ab60"
      },
      "source": [
        "np.shape(liwc_data_paragraphs)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(639, 95)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCSvy3essahT"
      },
      "source": [
        "## **Build and test LR model on the reduced dataset (only the most important features)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "DdpbmmGBrXhU",
        "outputId": "c3efca68-36d3-4e68-bf22-4914fcfb4ba1"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "shuffle(liwc_data[important_features]).head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>function</th>\n",
              "      <th>pronoun</th>\n",
              "      <th>i</th>\n",
              "      <th>we</th>\n",
              "      <th>you</th>\n",
              "      <th>shehe</th>\n",
              "      <th>they</th>\n",
              "      <th>ipron</th>\n",
              "      <th>article</th>\n",
              "      <th>prep</th>\n",
              "      <th>auxverb</th>\n",
              "      <th>conj</th>\n",
              "      <th>compare</th>\n",
              "      <th>interrog</th>\n",
              "      <th>affect</th>\n",
              "      <th>posemo</th>\n",
              "      <th>negemo</th>\n",
              "      <th>anx</th>\n",
              "      <th>sad</th>\n",
              "      <th>family</th>\n",
              "      <th>friend</th>\n",
              "      <th>female</th>\n",
              "      <th>male</th>\n",
              "      <th>cause</th>\n",
              "      <th>certain</th>\n",
              "      <th>differ</th>\n",
              "      <th>percept</th>\n",
              "      <th>see</th>\n",
              "      <th>hear</th>\n",
              "      <th>feel</th>\n",
              "      <th>sexual</th>\n",
              "      <th>drives</th>\n",
              "      <th>affiliation</th>\n",
              "      <th>power</th>\n",
              "      <th>reward</th>\n",
              "      <th>risk</th>\n",
              "      <th>focusfuture</th>\n",
              "      <th>leisure</th>\n",
              "      <th>home</th>\n",
              "      <th>money</th>\n",
              "      <th>informal</th>\n",
              "      <th>swear</th>\n",
              "      <th>assent</th>\n",
              "      <th>nonflu</th>\n",
              "      <th>Period</th>\n",
              "      <th>SemiC</th>\n",
              "      <th>QMark</th>\n",
              "      <th>Exclam</th>\n",
              "      <th>Dash</th>\n",
              "      <th>Apostro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1050</th>\n",
              "      <td>54.76</td>\n",
              "      <td>9.52</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.38</td>\n",
              "      <td>7.14</td>\n",
              "      <td>9.52</td>\n",
              "      <td>7.14</td>\n",
              "      <td>11.90</td>\n",
              "      <td>7.14</td>\n",
              "      <td>4.76</td>\n",
              "      <td>0.00</td>\n",
              "      <td>7.14</td>\n",
              "      <td>2.38</td>\n",
              "      <td>4.76</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>4.76</td>\n",
              "      <td>14.29</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.14</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.38</td>\n",
              "      <td>0.00</td>\n",
              "      <td>4.76</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.14</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>525</th>\n",
              "      <td>42.31</td>\n",
              "      <td>5.77</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.77</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>9.62</td>\n",
              "      <td>13.46</td>\n",
              "      <td>7.69</td>\n",
              "      <td>3.85</td>\n",
              "      <td>1.92</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3.85</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3.85</td>\n",
              "      <td>1.92</td>\n",
              "      <td>1.92</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.77</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.92</td>\n",
              "      <td>1.92</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.92</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.77</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3.85</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.92</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.77</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.92</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1791</th>\n",
              "      <td>48.57</td>\n",
              "      <td>22.86</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.43</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>11.43</td>\n",
              "      <td>0.00</td>\n",
              "      <td>17.14</td>\n",
              "      <td>2.86</td>\n",
              "      <td>5.71</td>\n",
              "      <td>5.71</td>\n",
              "      <td>2.86</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.71</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.86</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.86</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.57</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>279</th>\n",
              "      <td>44.83</td>\n",
              "      <td>8.05</td>\n",
              "      <td>3.45</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.30</td>\n",
              "      <td>2.30</td>\n",
              "      <td>8.05</td>\n",
              "      <td>14.94</td>\n",
              "      <td>3.45</td>\n",
              "      <td>4.60</td>\n",
              "      <td>2.30</td>\n",
              "      <td>2.30</td>\n",
              "      <td>4.60</td>\n",
              "      <td>2.30</td>\n",
              "      <td>2.30</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.15</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.30</td>\n",
              "      <td>2.30</td>\n",
              "      <td>2.30</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.05</td>\n",
              "      <td>1.15</td>\n",
              "      <td>5.75</td>\n",
              "      <td>1.15</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.15</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.60</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.45</td>\n",
              "      <td>1.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>291</th>\n",
              "      <td>45.24</td>\n",
              "      <td>7.14</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.76</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.38</td>\n",
              "      <td>11.90</td>\n",
              "      <td>11.90</td>\n",
              "      <td>9.52</td>\n",
              "      <td>4.76</td>\n",
              "      <td>4.76</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.38</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.38</td>\n",
              "      <td>2.38</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.38</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.38</td>\n",
              "      <td>2.38</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.90</td>\n",
              "      <td>0.00</td>\n",
              "      <td>11.90</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.38</td>\n",
              "      <td>2.38</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.14</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.38</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      function  pronoun     i   we    you  ...  SemiC  QMark  Exclam  Dash  Apostro\n",
              "1050     54.76     9.52  0.00  0.0   0.00  ...    0.0    0.0     0.0  0.00     0.00\n",
              "525      42.31     5.77  0.00  0.0   5.77  ...    0.0    0.0     0.0  1.92     0.00\n",
              "1791     48.57    22.86  0.00  0.0  11.43  ...    0.0    0.0     0.0  0.00     0.00\n",
              "279      44.83     8.05  3.45  0.0   0.00  ...    0.0    0.0     0.0  3.45     1.15\n",
              "291      45.24     7.14  0.00  0.0   4.76  ...    0.0    0.0     0.0  0.00     2.38\n",
              "\n",
              "[5 rows x 50 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sknDc9KCrsKO",
        "outputId": "950ee72a-a8c4-496a-b2fd-608dafd00410"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn import preprocessing as p\n",
        "\n",
        "\n",
        "VALIDATION_SPLIT = 0.2\n",
        "\n",
        "def build_logit(liwc_data, important_features):\n",
        "  # split the data into a training set and a validation set\n",
        "  min_max_scaler = p.MinMaxScaler()\n",
        "  liwc_shuffled = shuffle(liwc_data)\n",
        "  X = liwc_shuffled[important_features].values[:, 2:]\n",
        "  X = min_max_scaler.fit_transform(X)\n",
        "  Y = liwc_shuffled.values[:,1]\n",
        "  Y = y_to_binary(Y)\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=VALIDATION_SPLIT)\n",
        "  logreg = LogisticRegression()\n",
        "  logreg.fit(X_train, y_train)\n",
        "\n",
        "  y_pred = logreg.predict(X_test)\n",
        "  print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))\n",
        "  print('F1: {:.2f}'.format(metrics.f1_score(y_test, y_pred, average='weighted')))\n",
        "  # return logreg.score(X_test, y_test)\n",
        "  return (metrics.f1_score(y_test, y_pred, average='weighted'), y_test, y_pred)\n",
        "\n",
        "f1, y_test, y_pred = build_logit(liwc_data, important_features)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of logistic regression classifier on test set: 0.74\n",
            "F1: 0.73\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "am8SbmC5M7J8"
      },
      "source": [
        " **For N iterations check how important feature addition affects the mean accuracy of the model.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "Z6D-YbtUM5C_",
        "outputId": "97859df2-42fc-4fe7-d084-e37fba4af6d3"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "N = 90\n",
        "\n",
        "mean_f1 = []\n",
        "\n",
        "for i in range(3, N, 9):\n",
        "  print('Num features: %i' %i)\n",
        "  important_features = get_n_most_important(i)\n",
        "  f1, _, _ = build_logit(liwc_data, important_features)\n",
        "  # mean_accuracies.append(acc)\n",
        "  mean_f1.append(f1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num features: 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-2c8e6449063f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Num features: %i'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mimportant_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_n_most_important\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_logit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mliwc_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimportant_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;31m# mean_accuracies.append(acc)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-4de4a1fcdc01>\u001b[0m in \u001b[0;36mget_n_most_important\u001b[0;34m(num_features)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mrfe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRFE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mfit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;31m# print(\"Num Features: %s\" % (fit.n_features_))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/feature_selection/_rfe.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \"\"\"\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/feature_selection/_rfe.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, step_score)\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Fitting estimator with %d features.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msupport_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0;31m# Get coefs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1599\u001b[0m                       \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m                       sample_weight=sample_weight)\n\u001b[0;32m-> 1601\u001b[0;31m             for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n\u001b[0m\u001b[1;32m   1602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0mfold_coefs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfold_coefs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1039\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[1;32m    934\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"L-BFGS-B\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 936\u001b[0;31m                 \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"iprint\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0miprint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"gtol\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"maxiter\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    937\u001b[0m             )\n\u001b[1;32m    938\u001b[0m             n_iter_i = _check_optimize_result(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m--> 610\u001b[0;31m                                 callback=callback, **options)\n\u001b[0m\u001b[1;32m    611\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m         return _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_loss_and_grad\u001b[0;34m(w, X, y, alpha, sample_weight)\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m     \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_intercept_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_intercept_dot\u001b[0;34m(w, X, y)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0myz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     if (sparse.issparse(a) and sparse.issparse(b)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "w4hF5Se3SV8t",
        "outputId": "e972aae7-ab49-4bc0-bd6c-498a30257d28"
      },
      "source": [
        "plt.figure()\n",
        "plt.plot(range(3, N, 9),mean_f1, label='F1 change by number of features in LogisticRegression model')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXjU5b338fc3k30hITskQFjCFgRZBNzFhVBbl9qqUGurXfScak/r1ef0sVd7bI+nfc5zznPO6Vm0ntpFW4+yqLVStQWraF1ACCBIwBkChCyQSVgSJgnZZu7nj5ngEBKYJDPzm+X7uq5cJL/ZvpDhk1/u7/27bzHGoJRSKnYlWF2AUkqp0NKgV0qpGKdBr5RSMU6DXimlYpwGvVJKxbhEqwsYKD8/35SVlVldhlJKRZXt27cfM8YUDHZbxAV9WVkZVVVVVpehlFJRRUQOD3WbDt0opVSM06BXSqkYp0GvlFIxToNeKaViXEBBLyIrRMQuIjUi8vAgt08UkU0islNEdovIjb7jN4jIdhH5yPfntcH+CyillDq/C866EREb8DhwA9AAbBOR9caYvX53+wGwzhjzhIjMBl4DyoBjwE3GmCMiMgfYAJQE+e+glFLqPAI5o18M1BhjDhpjeoA1wC0D7mOAMb7Ps4EjAMaYncaYI77j1UCaiKSMvmyllFKBCiToS4B6v68bOPes/EfAF0WkAe/Z/DcHeZ7PATuMMd0DbxCR+0SkSkSqWlpaAipcqWj02kdHaWw9bXUZKs4Eqxm7CnjaGFMK3Ag8IyJnnltEKoB/Au4f7MHGmCeNMYuMMYsKCga9sEupqOfq6uWB53bwk1f3XvjOSgVRIEHfCEzw+7rUd8zfV4F1AMaYzUAqkA8gIqXAS8CXjDEHRluwUtFqf3M7xsDGaifNri6ry1FxJJCg3waUi8hkEUkGVgLrB9ynDrgOQERm4Q36FhHJAV4FHjbGvBe8spWKPo4mFwB9HsML2xssrkbFkwsGvTGmD3gQ74yZfXhn11SLyKMicrPvbt8Bvi4iu4DVwD3Gu0fhg8A04BER+dD3URiSv4lSEc7udJGWZGNxWS5rttbj8eg2nio8AlrUzBjzGt4mq/+xR/w+3wtcPsjjfgz8eJQ1KhUTHE4X5UWZ3LV0It9a8yHvHTjGleXak1Khp1fGKhUmDmc704uyqKwoZmx6Equ31lldkooTGvRKhcGJjh5aXN3MKMoiNcnG5xaUalNWhY0GvVJh4HB6G7HTi7MAWLVkojZlVdho0CsVBv1BP6PIG/RTCzJZMlmbsio8NOiVCgN7k4us1ESKxnyyAsgXlkyk7kQn7x04ZmFlKh5o0CsVBvud7cwoykJEzhzTpqwKFw16pULMGIPd6TozPt/Pvynb4jpnCSilgkaDXqkQa3Z103a698z4vL/+puzz2+sHeaRSwaFBr1SI2X1LH0wfJOi1KavCQYNeqRA7M7WyKHPQ27Upq0JNg16pEHM4XeRnJpOXOfieO9qUVaGmQa9UiNl9Sx8MRZuyKtQ06JUKIY/HsN/pOm/QA6xcrE1ZFToa9EqFUGPraTp73MwoPn/QTyvUpqwKHQ16pULokxk3gzdi/fU3Zd8/cDzUZak4o0GvVAg5mr1BX36BoRv4pCn73NbDoS5LxRkNeqVCyNHkYnx2KmNSky54X23KqlDRoFcqhOzO9nOWPjif/qasLl+sgkmDXqkQ6XN7ONDcPujSB0Ppb8qu3lqnTVkVNBr0SoVI7fFOetyegMbn/WlTVgWbBr1SIbJ/wGYjgdKmbHwyxnC6xx2S59agVypE7E4XIt7hmOHQpmz8OXy8g688vY1vrt4RkufXoFcqRBxOF5Ny00lLtg37sdqUjQ9dvW7+/c8ObvjpX9h66ARLp+SFpDeTGPRnVEoB3oulLrT0wVD8m7L3XzWFhAS58INUVNn0cTM/XF9N3YlObpo3nh98ehZFY1JD8lp6Rq9UCHT3uak93jnioAdtysaqhpOd3PfbKu59ehtJNuHZry3hv1bND1nIg57RKxUSB1s6cHvMsObQD+S/fPEV5flBrE5ZoafPwy/eOch/vbkfQfjuihl87YopJCeG/nxbg16pEHCMcMaNv/6m7NPv19Li6qYga/D17FXke6/mGH/38h4OtnRQWVHEIzdVUJKTFrbX16EbpULA3uQiMUGYnJ8xqufRpmx0a2rr4sHndnDXLz/A7TE8de8l/PzuRWENedAzeqVCwuF0MaUgY9S/lk8rzGTx5FzWbNOmbDTpdXv4zfu1/PR1B70ew0PXT+f+q6eQmjT8GVjBoGf0SoWA3eka9hWxQ7lryUQOH9embLTYeugEn/nPd/nxq/tYMiWPPz90Nd+6vtyykAc9o1cq6Dp7+qg/cZrbF04IyvNVVhSTo03ZiNfi6uYf/7iP3+1opCQnjSfvXsgNs4sQsf63MA16pYJsv7MdYFRTK/31N2V/o03ZiOT2GJ794DD/b4Odrl4337hmKg9eO4305MiJ14CGbkRkhYjYRaRGRB4e5PaJIrJJRHaKyG4RudF3PM93vF1EHgt28UpFInv/jJtRTK0caJU2ZSPSjrqT3PzYuzzycjVzS7P547eu4rsrZkZUyEMAZ/QiYgMeB24AGoBtIrLeGLPX724/ANYZY54QkdnAa0AZ0AX8HTDH96FUzHM0uUhJTGBibnrQnlObspHlZEcP//Snj1mzrZ6iMSn816r5fGbuuIgYphlMIGf0i4EaY8xBY0wPsAa4ZcB9DDDG93k2cATAGNNhjHkXb+ArFRfsThfTCjOxBTmMtSlrPY/HsGZrHcv+9S2e397A16+czBvfuYab5o2P2JCHwMboS4B6v68bgCUD7vMjYKOIfBPIAK4fThEich9wH8DEiROH81ClIs5+ZzuXTc0L+vNqU9Zaexrb+LuX97CzrpXFZbn8w61zgjo8F0rBml65CnjaGFMK3Ag8IyIBP7cx5kljzCJjzKKCgoIglaRU+LV19tJ0qmtUSx8Mpb8pu6G6SZcvDqO207388OU93PzYu9Sf6OTf7pjH2vuXRk3IQ2BB3wj4zxMr9R3z91VgHYAxZjOQCugph4o7jubRL31wPtqUDR9jDC9ub+C6f32LZ7Yc5u6lk3jjO9dw24LSiB6mGUwgQb8NKBeRySKSDKwE1g+4Tx1wHYCIzMIb9C3BLFSpaGBv8gZ9KM7o4eymrO4pGzr2Jhd3/nwL33l+F6Vj01n/4BX8/S1zyE5Lsrq0EbngGL0xpk9EHgQ2ADbg18aYahF5FKgyxqwHvgP8QkQewtuYvccYYwBEpBZvozZZRG4Flg+YsaNUzHA4XWSmJDI+O3RLzn5h8US+vfZDNh88zuXT9BfnYGrv7uPfX3fw1Pu1ZKUm8n9vu4g7Fk2I+llOAU32NMa8hnfKpP+xR/w+3wtcPsRjy0ZRn1JRxeF0UV6UGdJf7VfMKSbnD0k890GdBn2QGGN4ZfdRfvzqXpynulm1eALfrZzJ2Ixkq0sLisia1a9UFDPGYG9yUVlRHNLX0Stlg+tI62m++8Ju3q05RsX4Mfz3Fxcyf+JYq8sKKl3UTKkgOdbew8nO3qAtfXA+/U3ZF3doU3a0vv/SR+yoO8mjt1Sw/sErYi7kQYNeqaBxhGDpg6H0N2VXb9Wm7GjsaWxjk72FB5ZN40uXlgX9IrdIoUGvVJD0z7gpL8oMy+t9YbH3StnNB/VK2ZF6fFMNWamJ3H3pJKtLCSkNeqWCZH+zi7HpSRRkhmfMfMUc75Wyz31QF5bXizU1zS7+VN3Ely8tY0xqdE6bDJQGvVJBYm9yMb0oK2wX0+iVsqPzs00HSE208ZUrJltdSshp0CsVBMYYHM72sF8Wv2rxBG3KjkDd8U5e3nWEu5ZMJDdGplCejwa9UkFwpK2L9u6+sMy48TetMEubsiPwxNsHsInw9aumWF1KWGjQKxUEjv6lD8Ic9KBN2eE62naaF7c3cMclpRSNCd0VzJFEg16pIOifWjk9TDNu/J1pym7VpmwgnvzLQdzGcP9VU60uJWw06JUKArvTRdGYFHLSwz/e29+U3VjdxLF2bcqez7H2blZvrePWi0uYEMQdwCKdBr1SQeBwuiwZtum3avEEet26fPGF/PrdQ3T3efjGsvg5mwcNeqVGze0x7He2h2wN+kD0N2XXaFN2SG2dvfx282FuvGgcUwvCP8RmJQ16pUap/kQn3X0eS8/owduUrdWm7JB+s7mW9u4+HrhmmtWlhJ0GvVKjZHeGdrORQGlTdmgd3X38+r1DXD+rkNnjx1hdTthp0Cs1Sv1TK8sLrR0O0Kbs0J77oI7Wzl4eWBZ/Z/OgQa/UqNmdLibkppGRYv32DtqUPVdXr5sn3znI5dPyYnIJ4kBo0Cs1Sg6ny9JGrL9phVksLtOmrL/nq+ppcXXz4LJyq0uxjAa9UqPQ0+fhYEsH5RES9ABfWKJN2X69bg///fZBFk4ay9IpuVaXYxkNeqVGofZ4B30eEzFn9KBNWX8v7WyksfU0Dy6bFrZVRSORBr1So2C3cI2boWhT1svtMTzx1gEqxo/hmhkFVpdjKQ16pUbB4XRhSxCmFGRYXcpZtCkLr310lEPHOuL+bB406JUaFXuTi7K8dFKTbFaXcpZ4b8p6PIbHN9UwrTCTyopiq8uxnAa9UqOwv7k9ooZt/PU3ZbfEYVP2jY+b+bjJxQPLppIQoxt+D4cGvVIj1NXrpvZ4R8QG/Yo5xWSnJfFsnDVljTE8tqmGibnp3DR3vNXlRAQNeqVGqKa5HWMI+/aBgYrXpuy7NcfYVd/KX109lUSbRhxo0Cs1YpE442agLyyJv6bsY2/WUDwmlc8tLLG6lIihQa/UCDmcLpJtCZTlRe4GFvHWlN1We4IPDp3gvqumkJIYWQ1yK2nQKzVCDqeLKQUZET88sGrJhLhpyj72Zg15GcmsWjzR6lIiSmS/Q5WKYA5ne8SOz/v71JxxcdGU/aihjbcdLXzlismkJevZvD8NeqVGwNXVS2Pr6Ygen+8XL03ZxzfVMCY1kS9dOsnqUiJOQEEvIitExC4iNSLy8CC3TxSRTSKyU0R2i8iNfrd9z/c4u4hUBrN4pazicLYDRNQaN+fT35R9MUabsg6niz9VN3HPZWVkpSZZXU7EuWDQi4gNeBz4FDAbWCUiswfc7QfAOmPMfGAl8DPfY2f7vq4AVgA/8z2fUlHN4dtVKhqGbuCTpuzqGG3K/mxTDenJNu69fLLVpUSkQM7oFwM1xpiDxpgeYA1wy4D7GKB/f65s4Ijv81uANcaYbmPMIaDG93xKRTWH00Vako2SnDSrSwlYrDZlDx/vYP2uI3xx6STGZiRbXU5ECiToS4B6v68bfMf8/Qj4oog0AK8B3xzGY5WKOg6ni+lFmVF1eX1/UzbWli9+4q0DJNoS+NoVejY/lGA1Y1cBTxtjSoEbgWdEJODnFpH7RKRKRKpaWlqCVJJSoWNvitw1bobS35TdEENN2SOtp3lxRwN3LppA4ZhUq8uJWIGEcSMwwe/rUt8xf18F1gEYYzYDqUB+gI/FGPOkMWaRMWZRQUF8rxutIt/x9m6OtXdHzfi8v1hryj75l4MYA/dfPcXqUiJaIEG/DSgXkckikoy3ubp+wH3qgOsARGQW3qBv8d1vpYikiMhkoBzYGqzilbJC/4ybaDujh9hqyra4ulm9tY7Pzi+hdGzkXp0cCS4Y9MaYPuBBYAOwD+/smmoReVREbvbd7TvA10VkF7AauMd4VeM9098L/Al4wBjjDsVfRKlw2d8c+WvcnE9/U/aFHdF9Vv+rdw/R6/bw19dMtbqUiJcYyJ2MMa/hbbL6H3vE7/O9wOVDPPYnwE9GUaNSEcXe5GJMaiJFY1KsLmVEbrxoHKu31vO/X9yNALcvmnDBx0Sa1s4entlcy6fnjmdKQabV5UQ8vTJWqWFyOF3MKM6K2u3pUhJt/ObexVw+NZ+/fWE3z35w2OqShu3p92vp6HHzwDI9mw+EBr1Sw2CMwd7kitphm35pyTZ++eVFXDuzkO+/tIdfv3vI6pIC1t7dx1Pv1XL9rCJmFo+58AOUBr1Sw+E81c2prr6onHEzUGqSjf/+4kIqK4p49JW9/OytGqtLCsizWw7TdrqXB6+dZnUpUUODXoVUr9tDV2/s9N/7lz4oL4z+oAdITkzgsS8s4KZ54/nnP9n56esOjInc2ThdvW5+8c4hrizP5+IJOVaXEzUCasYqNVI/eGkP2+tO8vpDV0XtmLa//qCfXhQ7DcAkWwL/fufFpCQm8B9v7Ke7z8P/XjEjIr9fa7fVc6y9mweWzbe6lKiiQa9Cpq2zl5c+bKSnz0P1kVPMKcm2uqRRsze5yM9MIS8zOmfcDMWWIPzz5+aSkpjAf799gK5eNz+8aXZEhX1Pn4efv32AS8rGsmRyrtXlRBUNehUyL+/yhjzAxuqmmAh674yb2Dmb95eQIPz41jkkJybw1Hu19Lg9/PiWORGzns/vdzZypK2L/3PbRRH1Ayga6Bi9Cpm12+qZPW4MiyfnsnGv0+pyRs3jMTic0bfGzXCICI98ZjZ/fc1Unvugjr99YTfuCLiCts/t4Wdv1XBRSTZXT9dlUoZLg16FxJ7GNqqPnOLOSyawfHYRHze5OHy8w+qyRqWx9TSne90xHfTgDfvvVs7goeun8+KOBr699kN63R5La3r1o6PUHu/kgWXT9Gx+BDToVUisq6onOTGBWy8uobKiGIAN1U0WVzU69qboXvpgOESEb11fzsOfmskfdh3hwed20N1nzewpj8fws00HmF6UyfLZRZbUEO006FXQdfW6+f3ORlZUFJOdnsSE3HRmjxvDxuroHr6xx+CMmwv5q6un8sObZrOh2slfPbPdkqmyr+9zYne6+MY10yKmXxBtNOhV0G2obuJUVx93XvLJGirLK4rYXneSFlf0roPucLooyUmLuz1J7718Mj/57Bw22Vv42m+q6OzpC9trG2N4fFMNk/LS+czccWF73VijQa+Cbu22eibkpnHplLwzxyorijEGXo/ipqx36YP4OZv3d9eSSfzL7fN4/8Ax7vn1Ntq7wxP27+w/xu6GNv766qkk2jSuRkr/5VRQ1Z/o5P0Dx7l94YSzfs2eWZzFxNx0Nu6NznH6PreHgy0dcTE+P5TPLyzlP1bOZ3vdSe7+1Qe0ne4N+Ws+9mYN47JTuW1BachfK5Zp0Kuger6qHhFvKPgTEZbPLuL9muO4ukIfEMFWe7yTHrcnroMe4KZ543n8CwvY09jGXb/cwsmOnpC91tZDJ9hae4L7r5pCcqJG1Wjov54KGrfH8Pz2Bq4qL2B8Tto5t1fOKabH7WGTPfr2Be5f+iAWFjMbrRVzinny7kU4nO2s+sWWkPVdHttUQ35mMisXTwzJ88cTDXoVNO/sb+FoW9dZTVh/CyaOJT8zmY1ROM3S3uRCBKYVxucY/UDLZhby6y9fQu3xDlY+uZmmtq6gPv+u+lb+4mjhq1dMITXJFtTnjkca9Cpo1lXVk5uRzPWzBp/rbEsQrp9VxFv2FsvmZI+Uw+miLC9DQ8fPFeX5/PYrS2hq6+LOJzfTcLIzaM/9+KYastOS+OJSPZsPBg16FRTH27t5fa+TWy8uOe94amVFMe3dfbxfczyM1Y2ew+miXM/mz7F4ci7PfG0JJzp6uPPnW4Jy9bO9ycXGvU7uuaws7qayhooGvQqKl3Y20us2Qw7b9LtsWh4Zybaomn3T1eum9ninjs8PYcHEsaz++lI6evq44+ebOdDSPqrne3xTDRnJNu69vCw4BSoNejV6xhjWVdUzb0LOBcMwJdHGNTMLeX2vMyIWywrEwZYO3B4T9zNuzmdOSTZr7luK22O48+dbziwXMVy1xzp4ZfcRvnjpJHLSk4NcZfzSoFej9mF9Kw5nO3cuOv/ZfL/KimKOtfewo+5kiCsLDp1xE5iZxWNYc9+l2BJg5ZOb2dPYNuzneOKtAyTZEvjaFVNCUGH80qBXo7auqp60JBs3zQvsEvVlMwpIsknUzL6xO10k2YSyvAyrS4l40wozWXf/paQnJ/KFX2xh5zB+mDe2nubFHQ2svGQCBVmxtbGL1TTo1ah09vTxh11HufGicQE3zrJSk7hsaj4bqp0RvT9pv/1OF5PzM/SinQBNystg7f1LyUlP5u5fbWVb7YmAHvfk2wcQgfuunhriCuOPvnPVqLy6+yjt3X0XbMIOVFlRTN2JTj4e4VhuONmdLh2fH6bSsemsu/9SCsek8KVfbeW9mmPnvX+zq4s12+q5bX4pJYNcbKdGR4Nejcq6qnqm5GdwSdnYYT3uhtlFiBDxSxd3dPdRf+I0MzToh604O5W1913KxNx07n16G5vszUPe91fvHKLX7eGvr9Gz+VDQoFcjdqClnW21J7l90YRh7/pTkJXCwoljI34zkv3N3qmC07UROyIFWSmsvm8p5YWZ3PfbqkH7Mq2dPfzPlsPcNG88ZfnaBwkFDXo1Yuuq6rElCJ9bWDKixy+vKGLv0VPUnwjeFZXB5vANLekZ/cjlZiTz3NeWUjE+m288u4NXdh856/an3qulo8fNN66ZZlGFsU+DXo1Ir9vDi9sbWTajkMKs1BE9R/8Wg5G8cbjD6SIlMYEJuelWlxLVstOTeOari5k/MYe/Wb2T3+1oAMDV1ctT7x1i+ewinb4aQhr0akQ2fdzMsfbuYTdh/U3Ky2BmcVZED9/YnS7KizKx6RZ2o5aVmsRvvrKYpVPy+M7zu1i9tY7/2VLHqa4+HrxWz+ZDSYNejci6qnoKslJYNqNgVM+zfHYRVbUnON4emVsMOnTGTVClJyfy63su4erpBXzvdx/xX2/u56rpBcwtzbG6tJimQa+GrflUF5vsLXxuQemot3dbXlGMx8Ab+4aekWGV1s4enKe6dXw+yFKTbPz87oXcMLuIzh4339Sz+ZAL6H+piKwQEbuI1IjIw4Pc/lMR+dD34RCRVr/b/klE9vg+7gxm8coaL+xowO0x3LFo9Nu7VYwfQ0lOWkQO3zicOuMmVFISbTxx1wLe+l/XcElZrtXlxLzEC91BRGzA48ANQAOwTUTWG2P29t/HGPOQ3/2/Ccz3ff5pYAFwMZACvCUifzTGnArq30KFjTGG56saWFyWy5SC0S/bKyIsryji2Q/qaO/uIzPlgm/JsOlf40aHbkIj0Zag0ynDJJAz+sVAjTHmoDGmB1gD3HKe+68CVvs+nw38xRjTZ4zpAHYDK0ZTsLLW1kMnOHSsgztG0YQdqLKimJ4+D39xRNYWgw6ni8yURMZnj2xWkVKRIpCgLwHq/b5u8B07h4hMAiYDb/oO7QJWiEi6iOQDy4BzEkJE7hORKhGpammJrP/s6mxrq+rJTEnkxouKg/aciyaNJTcjOeKGb+xNLqYXZQ77YjClIk2wm7ErgReMMW4AY8xG4DXgfbxn+ZuBc/aQM8Y8aYxZZIxZVFAwulkcKnROdfXy2kdHuWneeNKTgzfEkmhL4LqZhbz5cTM9fZ6gPe9oGGNwOF06t1vFhECCvpGzz8JLfccGs5JPhm0AMMb8xBhzsTHmBkAAx0gKVdZ7ZddRuno9o5o7P5TKimJcXX1sORgZWwy2tHdzsrNXx+dVTAgk6LcB5SIyWUSS8Yb5+oF3EpGZwFi8Z+39x2wikuf7fC4wF9gYjMJV+K2tqmdGURbzSrOD/txXlOeTnmyLmOGb/f0zbjToVQy4YNAbY/qAB4ENwD5gnTGmWkQeFZGb/e66Elhjzl5gPAl4R0T2Ak8CX/Q9n4oy9iYXu+pbueOS4S9gFojUJBtXTy/g9b1OPBGwxWD/Vnga9CoWBDTQaox5De9Yu/+xRwZ8/aNBHteFd+aNinJrt9WTZBM+O39kC5gForKimD/uaeLDhlYWTBzessfB5nC6yM1IJj9T9y1V0U+vjFUX1N3n5qWdDSyfXUxuRuiCb9nMQhITJCKGb7ybjeiMGxUbNOjVBf15bzMnO3uDOnd+MNlpSVw6NY+NFm8xaIxhv7Ndh21UzNCgVxe0tqqe8dmpXDEtP+SvtbyimEPHOqjxbfhhhSNtXbR392nQq5ihQa/Oq7H1NO/sb+HziyaEZane5bOLACwdvjmz2YjOoVcxQoNendcLVd4NIm5fOPoFzAJRNCaViyfksMHCvWTt/WvcFGrQq9igQa+G5PEYnt9ez+VT88O6w1JlRTEfNbZxpPV02F7Tn6PJRfGYVLLTkyx5faWCTYNeDen9A8dpOHma24OwHPFwVFZ4h28G20g6HPp3lVIqVmjQqyGtraonOy3pzN6u4TKlIJPywkxLhm/cHkNNc7tuNqJiiga9GlRrZw8bqpu49eLxpCbZwv76yyuK2Fp7gpMdPWF93boTnXT3eXSzERVTNOjVoH6/s5GePk/I584PpbKiGLfH8MbH4d1isH/pAz2jV7FEg16dwxjD2qoG5pSMoWJ88BcwC8RFJdmMy04N+zTL/l2ldIxexRINenWOPY2n2Hf0FHcusuZsHnxbDM4u4p39LZzuOWcLg5CxO11MyE0L6nr7SllNg16dY21VHSmJCdx8cegWMAtEZUUxXb0e3g7jFoP7nS4dtlExR4NenaWr183LHx7hU3OKyU6zdh754sm5ZKclhW2aZU+fh4MtHbr0gYo5GvTqLH/ccxRXV59lTVh/ibYErptVyBsfN9PrDv0Wg4eOddDnMbr0gYo5GvTqLGu31TMxN52lk/OsLgXwDt+0ne5l66ETIX+tM0sf6Bm9ijEa9OqMw8c72HLwBHcsKiUhDAuYBeKq8gJSkxLCMvvG0eTCliBMKcgI+WspFU4a9OqMdVX1JAh8fqH1wzb90pJtXFVeEJY16h1OF2V56aQkhv8CMaVCSYNeAdDn9vDC9gaunl5AcXaq1eWcpbKimKZTXexuaAvp6zicLh2fVzFJg14B8Jf9LThPdXNnBDRhB7puViG2EG8xeLrHzeETnTo+r2KSBr0CYN22BvIykrl2ZpHVpZwjJz2ZJZNz2bg3dIuc1TS3Y4wufaBikwa94lh7N3/e5+S2BSUkJ0bmW6Kyopia5nYOtIRmi0H7maUPNOhV7InM/9UqrF7a0Uifx0TksE2/G0K8xeB+p4tkWwJleb3WU2AAABDxSURBVOHbYEWpcNGgj3PeBczqWTAxh2kRvHXe+Jw05pZmszFEa9TbnS6mFmaSaNP/Eir26Ls6zu2oa6WmuT2iz+b7VVYU82F9K01tXUF/bkeTixm6YqWKURr0cW7dtnrSk218eu54q0u5oP4tBl/fG9zhm1NdvRxp69LNRlTM0qCPYx3dfbyy+wifmTuOzJTIX5Z3akEmU/Izgj77Zn//0gcRPHSl1Gho0MexV3cfpaPHHRXDNuBbo76imM0HjtPW2Ru053U4vTN59GIpFas06OPY2qp6phZksGDiWKtLCVhlRRF9HsOb9uCd1dubXKQn2yjJSQvacyoVSTTo41RNs4vth09y5yUTEImMBcwCMa80h6IxKUGdfeNwuigvyoqYhdyUCjYN+ji1rqqBxAThtgWlVpcyLAkJwg2zi3jL3kJXb3C2GHQ4dcaNim0a9HGo1+3hdzsauG5WIfmZKVaXM2yVFcWc7nXzzv5jo36u4+3dHGvv0TVuVEwLKOhFZIWI2EWkRkQeHuT2n4rIh74Ph4i0+t32zyJSLSL7ROQ/JZrGCWLUG/uaOdbeEzVN2IGWTskjKzUxKFsM9jdiNehVLLvgnDoRsQGPAzcADcA2EVlvjNnbfx9jzEN+9/8mMN/3+WXA5cBc383vAlcDbwWpfjUC66rqKRqTwlXlBVaXMiJJtgSum1nIn/c56XN7RnU1q8M3tVJn3KhYFsj/kMVAjTHmoDGmB1gD3HKe+68CVvs+N0AqkAykAElA6JYgVBfU1NbFW/ZmPr+wNKov96+sKOZkZy/bak+O6nnsThfZaUkUZkXfEJZSgQrkf3oJUO/3dYPv2DlEZBIwGXgTwBizGdgEHPV9bDDG7BvkcfeJSJWIVLW0tAzvb6CG5cUdDXgM3B5Bu0iNxNUzCkhJHP0Wg96lD7KiauaRUsMV7FO6lcALxhg3gIhMA2YBpXh/OFwrIlcOfJAx5kljzCJjzKKCgugcTogGHo9hXVU9SybnUpYf3fuipicncmV5Pq/vHfkWg8YY7E4X5TrjRsW4QIK+EfA//Sv1HRvMSj4ZtgH4LLDFGNNujGkH/ghcOpJC1eh9cOgEh493Rm0TdqDlFcU0tp6m+sipET3eeaobV1efjs+rmBdI0G8DykVksogk4w3z9QPvJCIzgbHAZr/DdcDVIpIoIkl4G7HnDN2o8FhXVU9WSiKfmjPO6lKC4vpZRSTIyNeo799sRGfcqFh3waA3xvQBDwIb8Ib0OmNMtYg8KiI3+911JbDGnP179AvAAeAjYBewyxjzh6BVrwLWdrqX1z46ys0Xjyct2WZ1OUGRm5HMJWW5I75K1tGkQa/iQ0BLFhpjXgNeG3DskQFf/2iQx7mB+0dRnwqS9buO0N3niZlhm36VFcU8+speao91DLvvYHe6KMhKITcjOUTVKRUZond+nRqWddvqmVmcxUUl2VaXElTLK0a+xaDD6WK6NmJVHNCgjwN7j5zio8a2qFvALBClY9OpGD9m2GvUezyG/c52HbZRcUGDPg6sq6on2ZbArRcPevlD1KusKGZH3UmaXYFvMdhw8jSne93M0KBXcUCDPsZ19bp5aWcjyyuKGBujY9GVFcUYA68P46z+zIwbnVqp4oAGfYx7fa+TttO9MdeE9Te9KJNJeenDmn3Tv8ZNeaGO0avYp0Ef49ZV1VOSk8blU/OtLiVkRITKimLeP3CMU12BbTFob3JRkpNGVmpSiKtTynoa9DGs4WQn79Yc4/ZFpTG/e1JlRRG9bsOmj5sDur/OuFHxRIM+hj1f1QDA7Ytid9im3/wJY8nPTAlo9k2v28PBlg4dn1dxQ4M+Rrk9hhe2N3DFtPy42PT6zBaDHzdfcIvBw8c76HF7dMaNihsa9DGoq9fNL985SGPr6Zhuwg5UWVFER4+b9w+cf4tBe5PuKqXiS0BLIKjo0NTWxTNbalm9tZ4THT0smJjDDbOLrC4rbC6bmk9WSiIbq51cO3Pov7fd6SJBYJrOuFFxQoM+yhlj2FF3kqfeq+VPe5rwGMP1s4q49/LJLJ2SG3NXwp5PcmIC18ws5PW9Tn7yWYNtiAb0fqeLSXkZpCbFxuJuSl2IBn2U6u5z8+ruozz9fi27G9rISk3k3svL+NKlZUzITbe6PMtUVhTxh11H2H74JIsn5w56H7vOuFFxRoM+yjS7unh2Sx3PflDHsfZuphZk8A+3zuG2+SVkpOi385oZhSTbEthY3TRo0Hf1uqk91sFnLoqNNfmVCoQmQ5TYVd/K0+/X8sruI/S6DdfOLOSey8q4sjw/roZnLiQzJZHLp+WxYW8T3//0rHP+bQ60tOMxuvSBii8a9BGs1+3hj3uaePq9Q+yoayUzJZG7lkziy5eVMTnK93wNpcqKYjb97iP2HXUxe/yYs25z6K5SKg7FVNAfaGmnLC9jyCZctDje3s3qrXU8s+UwzlPdlOWl88ObZvP5haV6yX4Arp9dhLz0ERv3Ng0S9O0k2YSyPP1BqeJHzAT9iY4ervvXt8lItjGnJJt5E3KYV5rD3NJsSsemRcXwRvWRNp5+r5aXdx2hp8/DleX5/ONtF3HN9MKYX8IgmPIzU1g0aSwbqp18+/rpZ93maHIxJT+T5ES9hETFj5gJ+uTEBP719nnsamhlV4M3MHvcHsC7t+i80mzmluYwb4L3z/zMFIsr9upze3h9r5On3q9l66ETpCXZuGNRKV++tIxyHV4YscqKYn786j7qT3SeNQvJ7nQxf+JYCytTKvxiJugzUxL53MJSPrewFICePg8fN51iV0Mbu+tb2dXQyluOFvq3Li/JSWPehGzfWX8OF5VmkxnGWSutnT2s2VbPM5sP09h6mtKxaXz/xlncsWgC2ek6PDNay2d7g35DdRNfu3IKAO3dfTScPM3KOLpaWCmIoaAfKDkxgbm+EGfpJAA6uvvY09h25qx/d0Mrr33k3WtUBKYWZDLP76x/1rgsUhKDe1GNw+niqfdqeWlnA129HpZOyeWRm2Zz/ayiqO8tRJKJeenMLM5iY7XzTNDv71+DXn9TUnEmZoN+MBkpiSyZkseSKXlnjh1v72Z3Yxu7670/AN52NPPiDu+qj0k2Yda4Mcwtzfb9AMhhakHmsAPZ7TG8+XEzT79/iPdqjpOS6N3W757Ly5g1bsyFn0CNSGVFMf/55n6OtXeTn5nCfqd3jRtdzEzFm7gK+sHkZaawbEYhy2YUAt4lBY60dbHLN9yzu76N3+88wv9sqQM4q9nb/wNgqGbvqa5e1m2r57ebD1N3opPiMan8beUMVi2eSG6MbusXSSorivmPN/bzxj4nd14yEbvTRWpSQlxfOaziU9wH/UAiQklOGiU5adzou3rS4zEcPNbOrvq2IZu9n5z1Z1OQmcrz2+t5YXsDnT1uFk0ay3dXzKCyopgkm872CJdZ47IoHZvGhmpv0DucLsoLs3SITMUdDfoAJCQI0wqzmFaYNWizd1d9K7sbWnnbr9mbbEvgM/PGce9lk7moNNvC6uNX/xaDz2w+THt3H/YmF1eWF1hdllJhp0E/Qv7N3rt9zd52X7O37kQny2YUUpAVGVM441llRTG/evcQL3/YSLOrWxczU3FJgz6IMlMSWTolj6V+zV5lrYWTxpKXkcwTbx0AdI0bFZ90wFjFNFuCcP2sIhpOngZ0xo2KTxr0KuZVzvHuNpWVksi47FSLq1Eq/DToVcy7bGo+Gck2phdnRcWaR0oFm47Rq5iXmmTj72+ZQ26GLi2h4pMGvYoLn/dNi1UqHgU0dCMiK0TELiI1IvLwILf/VEQ+9H04RKTVd3yZ3/EPRaRLRG4N9l9CKaXU0C54Ri8iNuBx4AagAdgmIuuNMXv772OMecjv/t8E5vuObwIu9h3PBWqAjcH8CyillDq/QM7oFwM1xpiDxpgeYA1wy3nuvwpYPcjxzwN/NMZ0Dr9MpZRSIxVI0JcA9X5fN/iOnUNEJgGTgTcHuXklg/8AQETuE5EqEalqaWkJoCSllFKBCvb0ypXAC8YYt/9BERkHXARsGOxBxpgnjTGLjDGLCgp0LRKllAqmQIK+EfDfkqfUd2wwQ5213wG8ZIzpHV55SimlRiuQoN8GlIvIZBFJxhvm6wfeSURmAmOBzYM8x1Dj9koppULsgkFvjOkDHsQ77LIPWGeMqRaRR0XkZr+7rgTWGNO/UK+XiJTh/Y3g7WAVrZRSKnAyIJctJyItwGG/Q/nAMYvKOR+tK3CRWBNEZl2RWBNEZl2RWBNYV9ckY8ygTc6IC/qBRKTKGLPI6joG0roCF4k1QWTWFYk1QWTWFYk1QWTWpYuaKaVUjNOgV0qpGBcNQf+k1QUMQesKXCTWBJFZVyTWBJFZVyTWBBFYV8SP0SullBqdaDijV0opNQoa9EopFeMiOugvtA5+GOv4tYg0i8gev2O5IvK6iOz3/Tk2zDVNEJFNIrJXRKpF5FsRUleqiGwVkV2+uv7ed3yyiHzg+16u9V1lHVYiYhORnSLySgTVVCsiH/n2a6jyHbP6e5gjIi+IyMcisk9ELo2AmmYM2NvilIh8OwLqesj3Pt8jIqt973/L31cDRWzQ+62D/ylgNrBKRGZbVM7TwIoBxx4G3jDGlANv+L4Opz7gO8aY2cBS4AHfv4/VdXUD1xpj5uHdi2CFiCwF/gn4qTFmGnAS+GqY6wL4Ft6ru/tFQk0Ay4wxF/vNvbb6e/gfwJ+MMTOBeXj/zSytyRhj9/0bXQwsBDqBl6ysS0RKgL8BFhlj5gA2vCsERMr76hPGmIj8AC4FNvh9/T3gexbWUwbs8fvaDozzfT4OsFv87/Uy3s1hIqYuIB3YASzBe6Vg4mDf2zDVUoo3CK4FXgHE6pp8r1sL5A84Ztn3EMgGDuGbqBEJNQ1S43LgPavr4pMl3HPxbuL0ClAZCe+rgR8Re0bPMNbBt0iRMeao7/MmoMiqQnzrCc0HPiAC6vINkXwINAOvAweAVuNdNwms+V7+O/BdwOP7Oi8CagIwwEYR2S4i9/mOWfk9nAy0AE/5hrl+KSIZFtc0kP8quZbVZYxpBP4FqAOOAm3AdiLjfXWWSA76qGG8P7otmacqIpnAi8C3jTGnIqEuY4zbeH/FLsW7Q9nMcNfgT0Q+AzQbY7ZbWccQrjDGLMA7RPmAiFzlf6MF38NEYAHwhDFmPtDBgOEQi9/vycDNwPMDbwt3Xb5+wC14fziOBzI4d4g3IkRy0A9nHXwrOH0bqvRvrNIc7gJEJAlvyD9rjPldpNTVzxjTCmzC++trjoj071Ec7u/l5cDNIlKLdyvMa/GOQ1tZE3DmrBBjTDPeMefFWPs9bAAajDEf+L5+AW/wR8r76lPADmOM0/e1lXVdDxwyxrQY714bv8P7XrP8fTVQJAd9QOvgW2g98GXf51/GO0YeNiIiwK+AfcaYf4ugugpEJMf3eRrevsE+vIH/eSvqMsZ8zxhTaowpw/s+etMYc5eVNQGISIaIZPV/jnfseQ8Wfg+NMU1AvYjM8B26DthrZU0DDNzbwsq66oClIpLu+//Y/29l6ftqUFY3CS7Q7LgRcOAd4/2+hXWsxjsG14v3jOereMd43wD2A38GcsNc0xV4f03dDXzo+7gxAuqaC+z01bUHeMR3fAqwFajB+2t3ikXfy2uAVyKhJt/r7/J9VPe/xyPge3gxUOX7Hv4e74ZCltbkqysDOA5k+x2z+t/q74GPfe/1Z4AUq99Xg33oEghKKRXjInnoRimlVBBo0CulVIzToFdKqRinQa+UUjFOg14ppWKcBr1SSsU4DXqllIpx/x8v3wXCgJnecQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pO5StreQBvP"
      },
      "source": [
        "**Train on the given category set, then test on the external category.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 760
        },
        "id": "2BGke5dH_Fv_",
        "outputId": "eb2b5369-a26c-4b3f-a1c5-f7eaf0af6201"
      },
      "source": [
        "!pip install spacytextblob"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting spacytextblob\n",
            "  Downloading https://files.pythonhosted.org/packages/56/34/13b9d75a9e3ba30eac115dd0ecbe17d65921a721345b8d915b9ffccc0123/spacytextblob-0.1.7-py3-none-any.whl\n",
            "Requirement already satisfied: textblob<0.16.0,>=0.15.3 in /usr/local/lib/python3.7/dist-packages (from spacytextblob) (0.15.3)\n",
            "Collecting spacy<3.0.0,>=2.3.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/89/1539c4024c339650c222b0b2ca2b3e3f13523b7a02671f8001b7b1cee6f2/spacy-2.3.5-cp37-cp37m-manylinux2014_x86_64.whl (10.4MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4MB 6.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.7/dist-packages (from textblob<0.16.0,>=0.15.3->spacytextblob) (3.2.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.3.2->spacytextblob) (3.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.3.2->spacytextblob) (0.8.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.3.2->spacytextblob) (1.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.3.2->spacytextblob) (4.41.1)\n",
            "Collecting thinc<7.5.0,>=7.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/92/71ab278f865f7565c37ed6917d0f23342e4f9a0633013113bd435cf0a691/thinc-7.4.5-cp37-cp37m-manylinux2014_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 41.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.3.2->spacytextblob) (2.23.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.3.2->spacytextblob) (54.0.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.3.2->spacytextblob) (2.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.3.2->spacytextblob) (1.0.5)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.3.2->spacytextblob) (0.4.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.3.2->spacytextblob) (1.1.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.3.2->spacytextblob) (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.3.2->spacytextblob) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob<0.16.0,>=0.15.3->spacytextblob) (1.15.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<3.0.0,>=2.3.2->spacytextblob) (3.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.3.2->spacytextblob) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.3.2->spacytextblob) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.3.2->spacytextblob) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.3.2->spacytextblob) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<3.0.0,>=2.3.2->spacytextblob) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<3.0.0,>=2.3.2->spacytextblob) (3.7.4.3)\n",
            "Installing collected packages: thinc, spacy, spacytextblob\n",
            "  Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "Successfully installed spacy-2.3.5 spacytextblob-0.1.7 thinc-7.4.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "spacy",
                  "thinc"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMHiocjs_e0v"
      },
      "source": [
        "# The Model\r\n",
        "Features:\r\n",
        "- TFIDF\r\n",
        "- NER\r\n",
        "- POS\r\n",
        "- LIWC\r\n",
        "- sentiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADi-UtDH_rFN",
        "outputId": "63e7f606-59b9-4ce0-b737-33aa3ad2ae90"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\r\n",
        "# from sklearn.utils import shuffle\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn import metrics\r\n",
        "from sklearn import preprocessing as p\r\n",
        "\r\n",
        "VALIDATION_SPLIT = 0.1\r\n",
        "\r\n",
        "data = liwc_data_paragraphs\r\n",
        "Y = data['Rate']\r\n",
        "Y = y_to_binary(Y)\r\n",
        "\r\n",
        "np.shape(Y)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(639,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLB2fRE9AkMF"
      },
      "source": [
        "### **TFIDF**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T19kOeTZAmmT",
        "outputId": "1ed5cf45-568e-4305-c1bb-05acf66d64c2"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "import re\r\n",
        "import nltk\r\n",
        "\r\n",
        "nltk.download('punkt')\r\n",
        "\r\n",
        "from nltk.stem import PorterStemmer\r\n",
        "from nltk import word_tokenize, sent_tokenize\r\n",
        "\r\n",
        "corpus = data['Body']\r\n",
        "corpus_removed_numbers = [re.sub(r'\\d+', '', s) for s in corpus]\r\n",
        "\r\n",
        "corpus_tokenized = []\r\n",
        "stemmer= PorterStemmer()\r\n",
        "\r\n",
        "for s in corpus_removed_numbers:\r\n",
        "  tokens = word_tokenize(s)\r\n",
        "  stemmed_tokens = [stemmer.stem(word) for word in tokens]\r\n",
        "  corpus_tokenized.append(\" \".join(stemmed_tokens))\r\n",
        "\r\n",
        "vectorizer = TfidfVectorizer()\r\n",
        "X_tfidf = vectorizer.fit_transform(corpus_tokenized)\r\n",
        "X_tfidf = np.array(X_tfidf.toarray())\r\n",
        "\r\n",
        "np.shape(X_tfidf)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(639, 3352)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHhdzmScBb8r"
      },
      "source": [
        "### **LIWC**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfN8WBFMBd7L",
        "outputId": "d0ea32c9-cae0-40cd-9064-c45c169bce50"
      },
      "source": [
        "# important_features = get_n_most_important(50)\r\n",
        "X_liwc = data.values[:, 2:]\r\n",
        "\r\n",
        "np.shape(X_liwc)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(639, 93)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZpNdjMLADfT"
      },
      "source": [
        "### **Sentiment**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_guB3F6ACo4",
        "outputId": "ab56695e-8897-4b76-8ca3-497f64b3a557"
      },
      "source": [
        "import spacy\r\n",
        "from spacytextblob.spacytextblob import SpacyTextBlob\r\n",
        "\r\n",
        "nlp = spacy.load('en_core_web_sm')\r\n",
        "spacy_text_blob = SpacyTextBlob()\r\n",
        "nlp.add_pipe(spacy_text_blob)\r\n",
        "\r\n",
        "X_sentiment = []\r\n",
        "for s in corpus:\r\n",
        "  doc = nlp(s)\r\n",
        "  X_sentiment.append([doc._.sentiment.polarity,\r\n",
        "                     doc._.sentiment.subjectivity]\r\n",
        "                     )\r\n",
        "np.shape(X_sentiment)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(639, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CZN5Pq3I5cd",
        "outputId": "58b95b73-b2a7-4211-c17e-58524329c1bf"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "X = np.concatenate((X_tfidf, X_liwc, X_sentiment), axis=1)\n",
        "X = min_max_scaler.fit_transform(X)\n",
        "\n",
        "def eval_and_print_metrics(clf, X, Y):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=VALIDATION_SPLIT)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    # print(\"F1 score on test set: \"\n",
        "          # \"%0.3f\" % metrics.f1_score(y_test, y_pred, average='weighted'))\n",
        "    # print(\"-\" * 10)\n",
        "    return metrics.f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# clf = MLPClassifier(max_iter=3000, solver='adam', hidden_layer_sizes=(50,20)).fit(X_train, y_train)\n",
        "clf = LogisticRegression()\n",
        "\n",
        "f1s = []\n",
        "for i in range(0,20):\n",
        "  f1s.append(eval_and_print_metrics(clf, X, Y))\n",
        "\n",
        "print(\"Mean weighted f1: \", np.mean(f1s), \" STD: \", np.std(f1s))"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean weighted f1:  0.7090470026588408  STD:  0.05267316385822435\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5bHPD3tQoEB",
        "outputId": "da77e46e-0117-48e7-b931-9b9801941083"
      },
      "source": [
        "np.shape(X)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(639, 3447)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "-uJxgmQ5yFOl",
        "outputId": "2bbf8119-2b83-42a6-c85d-a15a16590dbb"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=VALIDATION_SPLIT)\n",
        "\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "logit_roc_auc = roc_auc_score(y_test, logreg.predict(X_test))\n",
        "fpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(X_test)[:,1])\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.savefig('Log_ROC')\n",
        "plt.show()\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, logreg.predict(X_test)))"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.26      0.36        23\n",
            "           1       0.69      0.90      0.78        41\n",
            "\n",
            "    accuracy                           0.67        64\n",
            "   macro avg       0.64      0.58      0.57        64\n",
            "weighted avg       0.65      0.67      0.63        64\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sk8O0VcMwZg"
      },
      "source": [
        "# RFE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lq8hv0ZMujI"
      },
      "source": [
        "from sklearn.feature_selection import RFE\r\n",
        "\r\n",
        "def get_n_most_important(num_features):\r\n",
        "  model = LogisticRegression(max_iter=10000)\r\n",
        "  rfe = RFE(model, num_features, verbose=0)\r\n",
        "  fit = rfe.fit(X, Y)\r\n",
        "\r\n",
        "  # print(\"Num Features: %s\" % (fit.n_features_))\r\n",
        "  # print(\"Selected Features: %s\" % (fit.support_))\r\n",
        "  # print(\"Feature Ranking: %s\" % (fit.ranking_))\r\n",
        "\r\n",
        "  features = liwc_data.columns.values[2:]\r\n",
        "  important_features = []\r\n",
        "\r\n",
        "  for f in list(zip(features, fit.support_)):\r\n",
        "    if f[1]:\r\n",
        "      important_features.append(f[0])\r\n",
        "\r\n",
        "  return important_features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h37C6qrEP8gZ"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "N = 3447\r\n",
        "interval = 100\r\n",
        "\r\n",
        "mean_f1 = []\r\n",
        "iter_range = range(100, N, interval)\r\n",
        "clf = LogisticRegression()\r\n",
        "\r\n",
        "for i in iter_range:\r\n",
        "  print('Num features: %i' %i)\r\n",
        "  important_features = get_n_most_important(i)\r\n",
        "  f1, _, _ = eval_and_print_metrics(clf, X, Y)\r\n",
        "  # mean_accuracies.append(acc)\r\n",
        "  mean_f1.append(f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwU3rJSsP-lt"
      },
      "source": [
        "plt.figure()\r\n",
        "plt.plot(iter_range,mean_f1, label='F1 change by number of features in LogisticRegression model')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}